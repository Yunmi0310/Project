{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion & Speed detection using openCV library\n",
    "1. Import a video stream\n",
    "2. The application track different models / objects in the videos. Draw one bounding box around the object and show the speed of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def video(image, video):\n",
    "    # read image patch to detect the moving train  \n",
    "    train_patch = cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "    #reshape the image(the number of color, width of patch, height of patch)\n",
    "    nc, wPatch, hPatch = train_patch.shape[::-1]\n",
    "    # split the patch only with red color \n",
    "    _, _, red_patch = cv2.split(train_patch)\n",
    "    \n",
    "    # capture the video \n",
    "    cap = cv2.VideoCapture(video)\n",
    "    # we have ret and frame being defined as the cap.read()\n",
    "    # ret is a boolean regarding whether or not there was a return at all, at the frame is each frame that is returned.\n",
    "    ret, frame_past = cap.read()\n",
    "    ret, frame_curr = cap.read()\n",
    "    old_centroid = None\n",
    "    \n",
    "    while (cap.isOpened()):\n",
    "        \n",
    "        # extract red channel of current frame\n",
    "        _, _, red_frame = cv2.split(frame_curr)\n",
    "\n",
    "        # Perform matching operations on red channel\n",
    "        res = cv2.matchTemplate(red_frame, red_patch, cv2.TM_CCOEFF_NORMED)\n",
    "        max_similarity = np.max(res)\n",
    "        # print(max_similarity)\n",
    "        \n",
    "        # similarity measure is above a threshold then train is detected\n",
    "        if max_similarity > 0.50:\n",
    "            loc = np.where(res >= max_similarity)\n",
    "            patch_loc = (loc[1][0], loc[0][0])  # when drawing x and y are inverted\n",
    "            cv2.rectangle(frame_curr, patch_loc, (patch_loc[0] + wPatch, patch_loc[1] + hPatch), (0, 255, 255), 10)\n",
    "            \n",
    "            new_centroid = np.array([patch_loc[0] + int(wPatch / 2), patch_loc[1] + int(hPatch / 2)])\n",
    "            #cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "            cv2.circle(frame_curr, tuple(new_centroid), 5, (0, 255, 255), -1)\n",
    "            cv2.putText(frame_curr, \"centroid\", (new_centroid[0] - 25, new_centroid[1] - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                    (0, 255, 255), 2)\n",
    "            \n",
    "            if old_centroid is not None:\n",
    "                # vector norm\n",
    "                distance_run = np.linalg.norm(new_centroid - old_centroid, 2)  # in terms of pixels\n",
    "                if distance_run > 5:\n",
    "                    \n",
    "                    # cv2.putText(image, text, org, font, fontScale, color, thickness)\n",
    "                    cv2.putText(frame_curr, \"Status: {}\".format('moving'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                            (0, 0, 255), 3)\n",
    "                    \n",
    "                    # 1pixel is 0.026cm, 30 frames per second \n",
    "                    speed = (distance_run*0.026)*30/100\n",
    "                    cv2.putText(frame_curr, \"Speed: {:.2f} m/s\".format(speed), (10,50), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                            (0, 0, 255), 3)\n",
    "                \n",
    "                else:\n",
    "                    cv2.putText(frame_curr, \"Status: {}\".format('stopped'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                            (0, 0, 255), 3)\n",
    "            old_centroid = np.array(new_centroid)  # update old_centroid\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            old_centroid = None  # update old_centroid\n",
    "            cv2.putText(frame_curr, \"Status: {}\".format('No train'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "            \n",
    "        cv2.imshow('final result', frame_curr)\n",
    "        ret, frame_curr = cap.read()\n",
    "            \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): # to stop reading video by pressing 'q' on keyboard\n",
    "            break\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video('train.png', 'VID_20181016_143349.mp4' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='final result_screenshot.png'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
